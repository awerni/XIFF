---
title: "E2E Machine Learning using XIFF"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{E2E Machine Learning using XIFF}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "CairoPNG",
  fig.height = 6,
  fig.width = 7,
  eval = FALSE
)
```

*The code in this vignette is not evaluated because it takes too much time to run. It is here only as a reference.*

# Preparing the data

```{r setup}
library(XIFF)
library(dplyr)
setDbOptions()
set.seed(123)

# Preparing data
cellline <- CLIFF::getWaterfallDataDepletion(ensg = "ENSG00000135679", study = "Avana", score = "ceres")
cellline <- cellline %>% filter(tumortype %in% c("skin cancer", "lung cancer",  "ovarian cancer", "pancreatic cancer"))
cellline <- cellline %>% filter(var < 0)

# Select sensitive and resistant celllines
# note that the number of resistant celllines is selected to be the same as number of sensistve celllines 
sensitive <- cellline %>% filter(var < -1) %>% select(celllinename) %>% pull %>% as.character()
resistant <- cellline %>% arrange(desc(var)) %>% head(length(sensitive)) %>% select(celllinename) %>% pull %>% as.character()
cs <- list(class1 = sensitive, class2 = resistant)
```

```{r}
# Hallmark gene set
geneSet <- CLIFF::getGSEAdata("human", "hallmark")[["HALLMARK_P53_PATHWAY"]]

# Gene Annotation
geneAnno <- CLIFF::getGeneAnno()[["human"]]

annoFocus <- CLIFF::getCellLineAnno("human")

# Get data and split it into train and validation set
cs <- getStashedData("0766b1")
cs <- split(cs$celllinename, cs$MDM2_class)
cs <- XIFF::makeClassAssignment(
  cs, classLabel = "sensitive"
)

print(cs)
```


```{r}
sets <- XIFF::splitTrainingValidationSets(cs, 0.2)
trainingSet <- sets$training
validationSet <- sets$validation
```


# Training the model using `buildMachineLearning`

```{r}
set.seed(123)
defaultFit <- XIFF::buildMachineLearning(
  cs = trainingSet,
  geneSet = geneSet,
  geneAnno = geneAnno,
  p_validation = 0.2
)

# model using caret functionality. It does not implement 
# model specific function is XIFF, but uses sensible defaults
glmnetFit <- XIFF::buildMachineLearning(
  cs = trainingSet,
  geneSet = geneSet,
  geneAnno = geneAnno,
  method = "glmnet",
  p_validation = 0.2
)
```
# Making Predictions

### Prediction just uses `S3 predict` method from `caret`.

```{r}
predict(defaultFit)
predict(glmnetFit)
```

### Prediction on model's validation set (note that each model has it's own validation created before training):

```{r}
# Random forest
## Getting data
modelValidationData <- getDataForModel(assignment = defaultFit$validationSet,
                                       features = defaultFit)
## Making predition
modelValidationData %>% select(celllinename, class) %>%
  mutate(predicted = predict(defaultFit, newdata = modelValidationData))

# GLMNET
## Getting data
modelValidationDataGlmnet <- getDataForModel(assignment = glmnetFit$validationSet,
                                       features = glmnetFit)
## Making predition
modelValidationDataGlmnet %>% select(celllinename, class) %>%
  mutate(predicted = predict(glmnetFit, newdata = modelValidationDataGlmnet))
```
### Using the validation set created at the beginning.

```{r}
# Getting all features from rf and glmnet models
# so the same data can be used in prediction
allFeatures <- list(defaultFit, glmnetFit) %>% 
  sapply("[[", "bestFeatures") %>%
  unlist() %>% unique()

modelValidationData <- getDataForModel(assignment = validationSet,
                                       features = allFeatures)

# Making the prediction for two models
prf <- predict(defaultFit, newdata = modelValidationData)
pglm <- predict(glmnetFit, newdata = modelValidationData)

# Adding the predictions to the table with celllinename and class
modelValidationData %>% dplyr::select(celllinename, class) %>%
  mutate(RandomForest = prf, Glmnet = pglm)

```

# Plots

## Basic Performance Plots

```{r}
library(tidyr)
generatePerformancePlot(defaultFit)
generatePerformancePlot(glmnetFit)
```
## Variable importance

```{r}
generateVarImpPlot(defaultFit)
generateVarImpPlot(glmnetFit)
```

## Error plot (random forest only)

```{r}
# For random forest only
generateErrorPlot(defaultFit)
```



```{r}
validationData <- getDataForModel(assignment = validationSet, features = defaultFit)
annoFocus <- CLIFF::getCellLineAnno("human") %>% dplyr::filter(celllinename %in% unlist(validationSet))


predictionSummary <- getPredictionSummary(
  items = validationData$celllinename,
  preds = predict(defaultFit, newdata = validationData),
  refs = validationData$class,
  positive_model = "sensitive",
  positive_cs = "sensitive",
  classes = c("positive", "negative"),
  classes_model = c("sensitive", "resistant"),
  classes_cs = c("sensitive", "resistant"),
  annoFocus = annoFocus
)

predictionSummary$res
predictionSummary$data
```


```{r}
df <- prepareTablePlotData(
  df = predictionSummary$data,
  positive_preds = "sensitive",
  positive_refs = "sensitive",
  labels_preds = c("sensitive", "resistant"),
  labels_refs = c("sensitive", "resistant"),
  labels = c("positive", "negative")
)
generateTablePlot(df)

df2 <- getPerformanceDataFrame(predictionSummary$res$table)
generateApplyPerformancePlot(df2)


gatherPredictionResults(predictions = list(predictionSummary))


validation <- validateModel(
  defaultFit,
  validationSet = validationSet,
  anno = annoFocus)
```


### Random Forest

```{r}
makeMlModelPlots(defaultFit, validationSet, annoFocus)
```

### Glmnet

```{r}
makeMlModelPlots(glmnetFit, validationSet, annoFocus)
```

# More examples.

## SVM

```{r}
svmFit <- XIFF::buildMachineLearning(
  cs = trainingSet,
  geneSet = geneSet,
  geneAnno = geneAnno,
  method = "svmLinear2"
)

makeMlModelPlots(svmFit, validationSet, annoFocus)
```

## CART

```{r}

if(XIFF::packageInstalled("rpart")) {
  rpartFit <- XIFF::buildMachineLearning(
    cs = trainingSet,
    geneSet = geneSet,
    geneAnno = geneAnno,
    method = "rpart"
  )
  makeMlModelPlots(rpartFit, validationSet, annoFocus)
}

```

# GREP method

### Auto verion

```{r}
set.seed(123)
logger::log_threshold(logger::TRACE)

grepFit <- XIFF::buildMachineLearning(
  cs = trainingSet,
  geneSet = geneSet,
  geneAnno = geneAnno,
  method = "GREP"
)

  
validation <- validateModel(
  grepFit,
  validationSet = validationSet,
  anno = annoFocus
)

makeMlModelPlots(grepFit, validationSet, annoFocus)

```

### Raw version

```{r}
set.seed(123)
logger::log_threshold(logger::TRACE)

grepFit <- XIFF::buildMachineLearning(
  cs = trainingSet,
  geneSet = geneSet,
  geneAnno = geneAnno,
  method = "glm",
  selectBestFeaturesFnc = getGrepFeatureSelection,
  maxFeatures = 600,
  .extraClass = "XiffGREP" # see inst/devel-notes/ml-custom-models.Rmd
)

annoFocus <- CLIFF::getCellLineAnno("human") %>%
  dplyr::filter(celllinename %in% unlist(validationSet))

valData <- getDataForModel(validationSet, grepFit)

validation <- validateModel(
  grepFit,
  validationSet = validationSet,
  anno = annoFocus
)

makeMlModelPlots(grepFit, validationSet, annoFocus)


```
